{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importattion des modules\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import string\n",
    "#from unidecode import unicode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des identififants\n",
    "api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxx\" \n",
    "api_secret  = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "access_token  = \"yyyyyyyyyyy-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "access_token_secret  = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling authentication with Twitter\n",
    "auth = tw.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapper for the API provided by Twitter\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "search_words = \"Les tirailleurs\"\n",
    "date_since = \"2022-12-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude retweets in our search\n",
    "new_search = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Define until what date we are looking for tweets\n",
    "date_until = \"\"\n",
    "\n",
    "# Total tweets to gather in our search\n",
    "totalTweets = 100000\n",
    "\n",
    "# Numbers of tweets to return per page, max is 100. Default is 15.\n",
    "count = 100\n",
    "\n",
    "# Filter by language\n",
    "lang = \"fr\" or \"en\"\n",
    "geocode = \"\"\n",
    "\n",
    "# Filter by recent, popular or mixed.\n",
    "result_type = \"recent\"\n",
    "include_entities = True\n",
    "\n",
    "# Set the name for CSV file  where the tweets will be saved\n",
    "filename = \"extractionTwitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the tweets using the search words and start date.\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q = search_words,\n",
    "              lang = lang,\n",
    "              since = date_since).items(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(key_word):\n",
    "    twitter_users = []\n",
    "    tweet_time = []\n",
    "    tweet_string = [] \n",
    "    like_numbers = []\n",
    "    retweete = []\n",
    "    numbers_retweet = []\n",
    "\n",
    "    \n",
    "    for tweet in tw.Cursor(api.search_tweets,q=key_word, count=1000).items(1000):\n",
    "            if (not tweet.retweeted) and ('RT @' not in tweet.text):\n",
    "                if tweet.lang == \"fr\":\n",
    "                    \n",
    "                    emoj = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        u\"\\U0001f926-\\U0001f937\"\n",
    "                        u\"\\U00010000-\\U0010ffff\"\n",
    "                        u\"\\u2640-\\u2642\" \n",
    "                        u\"\\u2600-\\u2B55\"\n",
    "                        u\"\\u200d\"\n",
    "                        u\"\\u23cf\"\n",
    "                        u\"\\u23e9\"\n",
    "                        u\"\\u231a\"\n",
    "                        u\"\\ufe0f\"  # dingbats\n",
    "                        u\"\\u3030\"\n",
    "                                    \"]+\", re.UNICODE)\n",
    "\n",
    "                    tweet_txt = emoj.sub(r'', tweet.user.name)\n",
    "                    tweet_txt = tweet_txt.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "                    tweet_string_txt = emoj.sub(r'', tweet.text.lower())\n",
    "                    twitter_users.append(tweet_txt)\n",
    "                    tweet_time.append(tweet.created_at)\n",
    "                    # Pour faciliter la tâche, on prend le miniscule des mots directement\n",
    "                    # Pour la suppression des ponctuations, ça créer par contre un souci pour les liens\n",
    "                    tweet_string.append(tweet_string_txt)\n",
    "                    like_numbers.append(tweet.favorite_count)\n",
    "                    retweete.append(tweet.retweeted)\n",
    "                    numbers_retweet.append(tweet.retweet_count)\n",
    "                                 \n",
    "    df = pd.DataFrame({'name':twitter_users, \n",
    "                       'time': pd.to_datetime(tweet_time), \n",
    "                       'tweet': tweet_string, \n",
    "                       'like':like_numbers,\n",
    "                       'retweet':retweete,\n",
    "                       'nb_retweet':numbers_retweet,\n",
    "                       })\n",
    "    \n",
    "    df.to_csv(f\"{key_word}.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci est un essaie pour les bases\n",
    "Je dois supprimer les ponctuations (sait comment faire, mais difficile avec les \"@\")\n",
    "Racinisation, get_token ? \n",
    "Doit on faire des DTM (comme dans le TD ?)\n",
    "\n",
    "test = df[\"tweet\"].iloc[1]\n",
    "final_test = []\n",
    "for mot in test.split():\n",
    "    if mot not in mots_vides:\n",
    "        final_test.append(mot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_related_tweets(\"Guerre en ukraine\")\n",
    "#df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecte to data\n",
    "#URI = \"mysql://root:master2@localhost/data?charset=utf8&use_unicode=1\"\n",
    "#con = sqlalchemy.create_engine(URI)\n",
    "\n",
    "#df[[\"name\", \"time\" ,\"tweet\", \"like\", \"retweet\", \"nb_retweet\"]].to_sql(name= \"tweet\", con = con, if_exists=\"append\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tirailleurs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c766268a8d8e9028bf2aee8d92f51ba242b73f097ccb08322d60fec14447b350"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
